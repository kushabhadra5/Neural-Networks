{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77184c7c",
   "metadata": {},
   "source": [
    "## Implemeting **Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a3bb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6332e5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KUSHAL\\AppData\\Local\\Temp\\ipykernel_20468\\613019470.py:1: DtypeWarning: Columns (81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('aps_data.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('aps_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe1d6da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1268</td>\n",
       "      <td>526</td>\n",
       "      <td>554</td>\n",
       "      <td>300</td>\n",
       "      <td>118</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>30</td>\n",
       "      <td>na</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>84</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>444</td>\n",
       "      <td>na</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1614</td>\n",
       "      <td>1144</td>\n",
       "      <td>3598</td>\n",
       "      <td>2460</td>\n",
       "      <td>1258</td>\n",
       "      <td>8524</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>82</td>\n",
       "      <td>na</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1464</td>\n",
       "      <td>...</td>\n",
       "      <td>1010</td>\n",
       "      <td>132</td>\n",
       "      <td>310</td>\n",
       "      <td>56</td>\n",
       "      <td>92</td>\n",
       "      <td>1292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>neg</td>\n",
       "      <td>31394</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>393008</td>\n",
       "      <td>207182</td>\n",
       "      <td>367634</td>\n",
       "      <td>267778</td>\n",
       "      <td>106778</td>\n",
       "      <td>48688</td>\n",
       "      <td>57146</td>\n",
       "      <td>638</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>neg</td>\n",
       "      <td>1598</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5298</td>\n",
       "      <td>3164</td>\n",
       "      <td>9710</td>\n",
       "      <td>47042</td>\n",
       "      <td>2296</td>\n",
       "      <td>1098</td>\n",
       "      <td>3288</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>neg</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2130706454</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>660</td>\n",
       "      <td>272</td>\n",
       "      <td>334</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>neg</td>\n",
       "      <td>32752</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>533772</td>\n",
       "      <td>37122</td>\n",
       "      <td>56252</td>\n",
       "      <td>23188</td>\n",
       "      <td>1138</td>\n",
       "      <td>134</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>neg</td>\n",
       "      <td>616</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4630</td>\n",
       "      <td>2268</td>\n",
       "      <td>4594</td>\n",
       "      <td>2760</td>\n",
       "      <td>2108</td>\n",
       "      <td>9308</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001  \\\n",
       "0      neg       6      0           0      0      0      0      0      0   \n",
       "1      neg      90      0           0     66      0      0      0      0   \n",
       "2      neg      30     na          16     14      0      0      0      0   \n",
       "3      neg     444     na          14     12      0      0      0      0   \n",
       "4      neg      82     na          12     10      0      0      0      0   \n",
       "...    ...     ...    ...         ...    ...    ...    ...    ...    ...   \n",
       "4995   neg   31394     na           0     na      0      0      0      0   \n",
       "4996   neg    1598     na           0     na      0      0      0      0   \n",
       "4997   neg      42      2  2130706454     56      0      0      0      0   \n",
       "4998   neg   32752     na           0     na      0      0      0      0   \n",
       "4999   neg     616      6          58     54      0      0      0      0   \n",
       "\n",
       "     ag_002  ...  ee_002  ee_003  ee_004  ee_005  ee_006 ee_007 ee_008 ee_009  \\\n",
       "0         0  ...      26       8      26      52       0      0      0      0   \n",
       "1         0  ...    1268     526     554     300     118    260      0      0   \n",
       "2         0  ...     480      84      74      50      46      0      0      0   \n",
       "3         0  ...    1614    1144    3598    2460    1258   8524    110      0   \n",
       "4      1464  ...    1010     132     310      56      92   1292      0      0   \n",
       "...     ...  ...     ...     ...     ...     ...     ...    ...    ...    ...   \n",
       "4995      0  ...  393008  207182  367634  267778  106778  48688  57146    638   \n",
       "4996      0  ...    5298    3164    9710   47042    2296   1098   3288    272   \n",
       "4997      0  ...     660     272     334      76      14      0      0      0   \n",
       "4998      0  ...  533772   37122   56252   23188    1138    134     22      0   \n",
       "4999      0  ...    4630    2268    4594    2760    2108   9308     64      0   \n",
       "\n",
       "     ef_000 eg_000  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "4995      0      0  \n",
       "4996      0      0  \n",
       "4997      0      0  \n",
       "4998      0      0  \n",
       "4999      0      0  \n",
       "\n",
       "[5000 rows x 171 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01740681",
   "metadata": {},
   "source": [
    "- Replacing 'na' value by numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26625b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('na',np.NaN)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "26e414e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000',\n",
       "       'ag_000', 'ag_001', 'ag_002',\n",
       "       ...\n",
       "       'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008',\n",
       "       'ee_009', 'ef_000', 'eg_000'],\n",
       "      dtype='object', length=171)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94685c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null data in columns\n",
      "class : 0.0\n",
      "aa_000 : 0.0\n",
      "ab_000 : 0.7698\n",
      "ac_000 : 0.0616\n",
      "ad_000 : 0.2472\n",
      "ae_000 : 0.0448\n",
      "af_000 : 0.0448\n",
      "ag_000 : 0.0116\n",
      "ag_001 : 0.0116\n",
      "ag_002 : 0.0116\n",
      "ag_003 : 0.0116\n",
      "ag_004 : 0.0116\n",
      "ag_005 : 0.0116\n",
      "ag_006 : 0.0116\n",
      "ag_007 : 0.0116\n",
      "ag_008 : 0.0116\n",
      "ag_009 : 0.0116\n",
      "ah_000 : 0.012\n",
      "ai_000 : 0.0112\n",
      "aj_000 : 0.0112\n",
      "ak_000 : 0.0768\n",
      "al_000 : 0.013\n",
      "am_0 : 0.0112\n",
      "an_000 : 0.013\n",
      "ao_000 : 0.0106\n",
      "ap_000 : 0.013\n",
      "aq_000 : 0.0106\n",
      "ar_000 : 0.0484\n",
      "as_000 : 0.0112\n",
      "at_000 : 0.0112\n",
      "au_000 : 0.0112\n",
      "av_000 : 0.0448\n",
      "ax_000 : 0.0448\n",
      "ay_000 : 0.0116\n",
      "ay_001 : 0.0116\n",
      "ay_002 : 0.0116\n",
      "ay_003 : 0.0116\n",
      "ay_004 : 0.0116\n",
      "ay_005 : 0.0116\n",
      "ay_006 : 0.0116\n",
      "ay_007 : 0.0116\n",
      "ay_008 : 0.0116\n",
      "ay_009 : 0.0116\n",
      "az_000 : 0.0116\n",
      "az_001 : 0.0116\n",
      "az_002 : 0.0116\n",
      "az_003 : 0.0116\n",
      "az_004 : 0.0116\n",
      "az_005 : 0.0116\n",
      "az_006 : 0.0116\n",
      "az_007 : 0.0116\n",
      "az_008 : 0.0116\n",
      "az_009 : 0.0116\n",
      "ba_000 : 0.0122\n",
      "ba_001 : 0.0122\n",
      "ba_002 : 0.0122\n",
      "ba_003 : 0.0122\n",
      "ba_004 : 0.0122\n",
      "ba_005 : 0.0122\n",
      "ba_006 : 0.0122\n",
      "ba_007 : 0.0122\n",
      "ba_008 : 0.0122\n",
      "ba_009 : 0.0122\n",
      "bb_000 : 0.012\n",
      "bc_000 : 0.0486\n",
      "bd_000 : 0.0486\n",
      "be_000 : 0.045\n",
      "bf_000 : 0.0448\n",
      "bg_000 : 0.013\n",
      "bh_000 : 0.013\n",
      "bi_000 : 0.0106\n",
      "bj_000 : 0.0106\n",
      "bk_000 : 0.376\n",
      "bl_000 : 0.4468\n",
      "bm_000 : 0.6546\n",
      "bn_000 : 0.7262\n",
      "bo_000 : 0.7664\n",
      "bp_000 : 0.792\n",
      "bq_000 : 0.8086\n",
      "br_000 : 0.821\n",
      "bs_000 : 0.0132\n",
      "bt_000 : 0.0024\n",
      "bu_000 : 0.0128\n",
      "bv_000 : 0.0128\n",
      "bx_000 : 0.0576\n",
      "by_000 : 0.0086\n",
      "bz_000 : 0.0484\n",
      "ca_000 : 0.0766\n",
      "cb_000 : 0.0132\n",
      "cc_000 : 0.0576\n",
      "cd_000 : 0.0122\n",
      "ce_000 : 0.0448\n",
      "cf_000 : 0.2472\n",
      "cg_000 : 0.2472\n",
      "ch_000 : 0.2472\n",
      "ci_000 : 0.0076\n",
      "cj_000 : 0.0076\n",
      "ck_000 : 0.0076\n",
      "cl_000 : 0.1556\n",
      "cm_000 : 0.1592\n",
      "cn_000 : 0.0122\n",
      "cn_001 : 0.0122\n",
      "cn_002 : 0.0122\n",
      "cn_003 : 0.0122\n",
      "cn_004 : 0.0122\n",
      "cn_005 : 0.0122\n",
      "cn_006 : 0.0122\n",
      "cn_007 : 0.0122\n",
      "cn_008 : 0.0122\n",
      "cn_009 : 0.0122\n",
      "co_000 : 0.2472\n",
      "cp_000 : 0.0484\n",
      "cq_000 : 0.0128\n",
      "cr_000 : 0.7698\n",
      "cs_000 : 0.0116\n",
      "cs_001 : 0.0116\n",
      "cs_002 : 0.0116\n",
      "cs_003 : 0.0116\n",
      "cs_004 : 0.0116\n",
      "cs_005 : 0.0116\n",
      "cs_006 : 0.0116\n",
      "cs_007 : 0.0116\n",
      "cs_008 : 0.0116\n",
      "cs_009 : 0.0116\n",
      "ct_000 : 0.23\n",
      "cu_000 : 0.23\n",
      "cv_000 : 0.23\n",
      "cx_000 : 0.23\n",
      "cy_000 : 0.23\n",
      "cz_000 : 0.23\n",
      "da_000 : 0.23\n",
      "db_000 : 0.23\n",
      "dc_000 : 0.23\n",
      "dd_000 : 0.0448\n",
      "de_000 : 0.0484\n",
      "df_000 : 0.0722\n",
      "dg_000 : 0.0722\n",
      "dh_000 : 0.0722\n",
      "di_000 : 0.0722\n",
      "dj_000 : 0.0722\n",
      "dk_000 : 0.0722\n",
      "dl_000 : 0.0722\n",
      "dm_000 : 0.0722\n",
      "dn_000 : 0.0128\n",
      "do_000 : 0.0486\n",
      "dp_000 : 0.0486\n",
      "dq_000 : 0.0486\n",
      "dr_000 : 0.0486\n",
      "ds_000 : 0.0486\n",
      "dt_000 : 0.0486\n",
      "du_000 : 0.0486\n",
      "dv_000 : 0.0486\n",
      "dx_000 : 0.0484\n",
      "dy_000 : 0.0484\n",
      "dz_000 : 0.0484\n",
      "ea_000 : 0.0484\n",
      "eb_000 : 0.0722\n",
      "ec_00 : 0.1674\n",
      "ed_000 : 0.1556\n",
      "ee_000 : 0.0116\n",
      "ee_001 : 0.0116\n",
      "ee_002 : 0.0116\n",
      "ee_003 : 0.0116\n",
      "ee_004 : 0.0116\n",
      "ee_005 : 0.0116\n",
      "ee_006 : 0.0116\n",
      "ee_007 : 0.0116\n",
      "ee_008 : 0.0116\n",
      "ee_009 : 0.0116\n",
      "ef_000 : 0.0484\n",
      "eg_000 : 0.0484\n"
     ]
    }
   ],
   "source": [
    "rows_df = df.shape[0]\n",
    "\n",
    "print(\"Percentage of null data in columns\")\n",
    "for column in df.columns:\n",
    "    print(f\"{column} : {(df[column].isnull().sum()/rows_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2b301",
   "metadata": {},
   "source": [
    " - Creating list of columns having less than $20%$ of **Null** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f3ce9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_column_required = [column for column in df.columns if df[column].isnull().sum()/len(df[column])<0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9b0c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns in original dataframe: 171\n",
      "Required number of columns from original dataframe: 147\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of columns in original dataframe: {len(df.columns)}\")\n",
    "print(f\"Required number of columns from original dataframe: {len(list_column_required)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108dddaa",
   "metadata": {},
   "source": [
    " - List of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b234dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [column for column in list_column_required if column != 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b93d0b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying total number of features in dataframe after feature reduction: 171\n"
     ]
    }
   ],
   "source": [
    "print(f\"Verifying total number of features in dataframe after feature reduction: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabb4b4",
   "metadata": {},
   "source": [
    " - Imputing the dataset using KNNImputer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c64a9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "#Applying fit_transform()\n",
    "input_features_data = knn_imputer.fit_transform(df[input_features])\n",
    "#Converting the imputed version of DataFrame back to DataFrame as the return type of KNNInputer() is numpy.array\n",
    "df[input_features] = pd.DataFrame(input_features_data, columns=input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05613ec1",
   "metadata": {},
   "source": [
    "Separating dependent and independent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8a019420",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[input_features]\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2954be4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    neg\n",
       "1    neg\n",
       "2    neg\n",
       "3    neg\n",
       "4    neg\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de86e7",
   "metadata": {},
   "source": [
    " - Here, the target dataframe 'y' is a binary category so we'll encode it in numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "acf6e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace('neg', 0)\n",
    "y = y.replace('pos', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c6996996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23c461",
   "metadata": {},
   "source": [
    "### Implementing train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8bccb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "48286524",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e1b23f",
   "metadata": {},
   "source": [
    "### Scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "443ad19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce5ee93a",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "981b40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac489c7",
   "metadata": {},
   "source": [
    "1. `tensorflow.keras.models.Sequential` is a class in the TensorFlow library (specifically, the Keras API within TensorFlow) used for creating linear stack models, where each layer has exactly one input tensor and one output tensor. It is a simple way to build neural networks by adding one layer at a time.\n",
    "\n",
    "2. `tensorflow.keras.models.load_model` is a function in TensorFlow's Keras API that allows you to load a saved Keras model from a file. This function is used when you want to reuse a previously trained model or share your model with others without needing to retrain it.\n",
    "\n",
    "3. `tensorflow.keras.layers.Dense` is a class in TensorFlow, a popular deep learning library, specifically in the Keras API. It represents a fully connected (dense) neural network layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "69c6d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 146))\n",
    "\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    " \n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fcd02f",
   "metadata": {},
   "source": [
    "### Understanding the construction of the neural network:\n",
    "\n",
    "```python\n",
    "classifier=Sequential()\n",
    "```\n",
    "Here, we are creating an object `classifier` having an instannce of `tensorflow.keras.models.Sequential` which will allow us to create interconnected layers in the neural network. \n",
    "\n",
    "```python\n",
    "classifier.add(Dense(units=10,kernel_initializer='he_uniform',activation='relu',input_dim =146))\n",
    "```\n",
    "\n",
    "As the classifier object is the instance of Sequential Neural Network, to create layers for the neural network. Here, we are creating the first layer i.e. input layer of $146$ dimension and each neuron will be having $10$ outputs. Here, `'he_normal'` been used as weight initialization technique as the activation is `'relu'`.\n",
    "\n",
    "```python\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "```\n",
    "\n",
    "Here, we are creating the second layer where each neuron will be having $10$ outputs, `'he_normal'` as weight initialization technique and `'relu'` as activation function.\n",
    "\n",
    "```python\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "```\n",
    "\n",
    "Here, we are creating the third layer where it will produce the output. Since its a classification thus third layer will be having one output. Since, the third layer will do the final classification, thus we are using `'sigmoid'` as activation function and `'glorot_normal'` as kernel_initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b2279df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed61c26",
   "metadata": {},
   "source": [
    "Here, we are compiling the created neural network, for updation of parameters(weights and bias) we'll be using `'binary_crossentropy'` as loss function and `'adam'` as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "08761fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 10)                1470      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1591 (6.21 KB)\n",
      "Trainable params: 1591 (6.21 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "40bac600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.engine.sequential.Sequential"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614f6f6",
   "metadata": {},
   "source": [
    "## Initializing the training of model using Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50eb829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 13ms/step - loss: 0.5144 - accuracy: 0.8839 - val_loss: 0.3488 - val_accuracy: 0.9350\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9582 - val_loss: 0.2133 - val_accuracy: 0.9767\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9807 - val_loss: 0.1575 - val_accuracy: 0.9800\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1322 - accuracy: 0.9846 - val_loss: 0.1275 - val_accuracy: 0.9817\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9861 - val_loss: 0.1079 - val_accuracy: 0.9825\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9879 - val_loss: 0.0958 - val_accuracy: 0.9833\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9886 - val_loss: 0.0828 - val_accuracy: 0.9842\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9889 - val_loss: 0.0766 - val_accuracy: 0.9817\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9896 - val_loss: 0.0682 - val_accuracy: 0.9825\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9900 - val_loss: 0.0648 - val_accuracy: 0.9825\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9900 - val_loss: 0.0558 - val_accuracy: 0.9842\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9914 - val_loss: 0.0525 - val_accuracy: 0.9825\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9911 - val_loss: 0.0493 - val_accuracy: 0.9858\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 0.0485 - val_accuracy: 0.9850\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9914 - val_loss: 0.0457 - val_accuracy: 0.9867\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.0436 - val_accuracy: 0.9875\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9929 - val_loss: 0.0450 - val_accuracy: 0.9867\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0425 - val_accuracy: 0.9867\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0491 - val_accuracy: 0.9858\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0446 - val_accuracy: 0.9875\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0454 - val_accuracy: 0.9858\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0461 - val_accuracy: 0.9850\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0432 - val_accuracy: 0.9858\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.0491 - val_accuracy: 0.9850\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0476 - val_accuracy: 0.9858\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0517 - val_accuracy: 0.9867\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.0529 - val_accuracy: 0.9858\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0508 - val_accuracy: 0.9867\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.0537 - val_accuracy: 0.9858\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0540 - val_accuracy: 0.9858\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9986 - val_loss: 0.0572 - val_accuracy: 0.9867\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.0590 - val_accuracy: 0.9850\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.0618 - val_accuracy: 0.9858\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.0627 - val_accuracy: 0.9858\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0663 - val_accuracy: 0.9858\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0638 - val_accuracy: 0.9858\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0646 - val_accuracy: 0.9875\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0701 - val_accuracy: 0.9858\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0673 - val_accuracy: 0.9867\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0697 - val_accuracy: 0.9867\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0714 - val_accuracy: 0.9875\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0716 - val_accuracy: 0.9867\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0756 - val_accuracy: 0.9867\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0760 - val_accuracy: 0.9875\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0775 - val_accuracy: 0.9867\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0805 - val_accuracy: 0.9867\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0748 - val_accuracy: 0.9867\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0861 - val_accuracy: 0.9867\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0772 - val_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "ann_model=classifier.fit(X_train,y_train,batch_size=100,epochs=50,validation_split=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04c1b2",
   "metadata": {},
   "source": [
    " - To check the metrics of our neural network model, we will be using the `'history'` argument to retrieve the following keys:\n",
    "\n",
    "    - `'loss'`: The value of the loss function computed on the training data at each epoch during training. The loss function measures how well the model is performing on the training data, and the goal of training is to minimize this value.\n",
    "\n",
    "    - `'accuracy'`: The value of the accuracy metric computed on the training data at each epoch during training. This represents the proportion of correctly predicted samples in the training data.\n",
    "\n",
    "    - `'val_loss'`: The value of the loss function computed on the validation data at each epoch during training. The validation loss provides an indication of how well the model is generalizing to new, unseen data. It is used to detect overfitting, where the model performs well on the training data but poorly on new data.\n",
    "\n",
    "    - `'val_accuracy'`: The value of the accuracy metric computed on the validation data at each epoch during training. Similar to 'val_loss', this metric helps to assess the model's generalization performance on unseen data.\n",
    "\n",
    "\n",
    "These keys provide valuable information about the model's performance during training and validation. By analyzing these metrics across epochs, you can gain insights into how well the model is learning and whether it is overfitting or underfitting. For example:\n",
    "    \n",
    "   1. If the training loss is decreasing, and both training and validation accuracy are increasing, it indicates that the model is learning effectively and generalizing well to new data.\n",
    "\n",
    "   2. If the training loss is decreasing, but the validation loss starts increasing or remains constant, while validation accuracy decreases, it suggests that the model might be overfitting to the training data.\n",
    "\n",
    "   3. If both the training and validation loss are high and accuracy is low, it could indicate that the model is underfitting and not learning the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ffdc88cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8839285969734192,\n",
       " 0.958214282989502,\n",
       " 0.9807142615318298,\n",
       " 0.9846428632736206,\n",
       " 0.9860714077949524,\n",
       " 0.9878571629524231,\n",
       " 0.9885714054107666,\n",
       " 0.9889285564422607,\n",
       " 0.989642858505249,\n",
       " 0.9900000095367432,\n",
       " 0.9900000095367432,\n",
       " 0.991428554058075,\n",
       " 0.9910714030265808,\n",
       " 0.9917857050895691,\n",
       " 0.991428554058075,\n",
       " 0.991428554058075,\n",
       " 0.9928571581840515,\n",
       " 0.9932143092155457,\n",
       " 0.993571400642395,\n",
       " 0.9942857027053833,\n",
       " 0.9942857027053833,\n",
       " 0.9946428537368774,\n",
       " 0.996071457862854,\n",
       " 0.9957143068313599,\n",
       " 0.9967857003211975,\n",
       " 0.9967857003211975,\n",
       " 0.9978571534156799,\n",
       " 0.9978571534156799,\n",
       " 0.9978571534156799,\n",
       " 0.9978571534156799,\n",
       " 0.9978571534156799,\n",
       " 0.9985714554786682,\n",
       " 0.9985714554786682,\n",
       " 0.9985714554786682,\n",
       " 0.9985714554786682,\n",
       " 0.9985714554786682,\n",
       " 0.9985714554786682,\n",
       " 0.9985714554786682,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176,\n",
       " 0.9989285469055176]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.history['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6721b",
   "metadata": {},
   "source": [
    " - **Plotting the accuracy of the model corresponding to each epochs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1d90eb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(ann_model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(ann_model.history['accuracy'])\n",
    "plt.plot(ann_model.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4019a904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(ann_model.history['loss'])\n",
    "plt.plot(ann_model.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23180a6c",
   "metadata": {},
   "source": [
    "The training loss and both training and validation accuracy are constant in an artificial neural network, it suggests that the model has likely reached a plateau and is no longer learning from the data. This situation can occur for various reasons, and it's essential to investigate further to understand the potential issues. \n",
    "\n",
    "Here are some possible reasons for a constant training loss and accuracy:\n",
    "\n",
    " - **Convergence to a Local Minimum**: \n",
    " \n",
    "    The model might have converged to a local minimum in the loss landscape, where the optimization algorithm cannot make further progress. In such cases, the model might be stuck in a suboptimal solution, preventing it from achieving better performance.\n",
    "\n",
    " - **Incorrect Model Complexity**: \n",
    " \n",
    "    The model might be too simple to capture the underlying patterns in the data adequately. If the model is not complex enough, it may struggle to generalize well to the data, leading to constant performance metrics.\n",
    "\n",
    " - **Learning Rate Too Small**: \n",
    " \n",
    "    A very small learning rate could cause the optimization process to progress very slowly, leading to slow or no improvement in the model's performance.\n",
    "\n",
    " - **Vanishing or Exploding Gradients**: \n",
    " \n",
    "    Issues like vanishing or exploding gradients can hamper the training process, preventing the model from learning effectively.\n",
    "\n",
    " - **Data Issues**: \n",
    " \n",
    "    Low-quality or insufficient training data could hinder the learning process and result in constant performance metrics.\n",
    "\n",
    "To address this issue, you can try the following steps:\n",
    "\n",
    " - **Adjust Model Complexity**: \n",
    " \n",
    "    If the model is too simple, consider increasing its complexity by adding more layers, neurons, or using a more advanced architecture.\n",
    "\n",
    " - **Learning Rate Tuning**: \n",
    " \n",
    "    Experiment with different learning rates to find an optimal value that allows the model to make meaningful updates during training.\n",
    "\n",
    " - **Batch Normalization**: \n",
    " \n",
    "    Consider adding batch normalization layers, which can help stabilize training by normalizing the inputs to each layer.\n",
    "\n",
    " - **Weight Initialization**: \n",
    " \n",
    "    Ensure that the initial weights of the neural network are appropriate, as improper initialization can impact training.\n",
    "\n",
    " - **Data Augmentation**: \n",
    " \n",
    "    If you have limited data, data augmentation techniques can help artificially expand the dataset and potentially improve the model's generalization.\n",
    "\n",
    " - **Different Optimizers**: \n",
    " \n",
    "    Try different optimization algorithms like Adam, RMSprop, or SGD with momentum, as they might behave differently on your specific problem.\n",
    "\n",
    " - **Early Stopping**: \n",
    " \n",
    "    Implement early stopping to stop training if the model's performance on the validation set does not improve for a certain number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0109005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9fcca",
   "metadata": {},
   "source": [
    "Here we are going to compare the y_predict with a threshold value i.e. $0.5$.\n",
    "\n",
    "For more information regarding the selection of this threshold value, please refer to the following blog: https://www.evidentlyai.com/classification-metrics/classification-threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2c92e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if result > 0.5 else 0 for result in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d8f5d6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "36ce55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "64114c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ea6442d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[977,   8],\n",
       "       [ 10,   5]], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260409ec",
   "metadata": {},
   "source": [
    " - Hyperparameter Tuning using Keras Tuner\n",
    "\n",
    "    For this we will require another library i.e. keras-tuner. So, we'll be installing this library.\n",
    "    \n",
    "    ```bash\n",
    "    !pip install keras-tuner --upgrade\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f521c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5746260",
   "metadata": {},
   "source": [
    " - Constructing a function for hyperparameter tunning for the neural network:\n",
    "\n",
    " For more details you can refer this link: https://keras.io/keras_tuner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9a78bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "  #1st layer of neural network\n",
    "  model.add(Dense(hp.Choice(\"units\", [8,16,32,64]),\n",
    "                  kernel_initializer = 'he_uniform',\n",
    "                  activation='relu',\n",
    "                  input_dim = 146,))\n",
    "  #2nd layer of neural network\n",
    "  model.add(Dense(hp.Choice(\"units\", [8,16,32,64]),\n",
    "                  kernel_initializer = 'he_uniform',\n",
    "                  activation='relu',))\n",
    "  #3rd layer of neural network(i.e. output layer)\n",
    "  model.add(Dense(1,\n",
    "                  activation='sigmoid'))\n",
    "\n",
    "  \n",
    "    #Optimizers to be used in different different layers of neural network\n",
    "  optimizer = hp.Choice(\"optimizer\", values =['adam', 'sgd', 'rmsprop', 'adadelta'])\n",
    "  #Loss function to be used in different different layers of neural network\n",
    "  loss = hp.Choice(\"loss\", values =['binary_crossentropy', 'hinge', 'sigmoid_focal_crossentropy', 'squared_hinge', 'kullback_leibler_divergence', 'mean_squared_error'])\n",
    "  #Constructing the neural network model\n",
    "  model.compile(optimizer = optimizer, loss = loss, metrics = 'accuracy')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1e5099a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(build_model, \n",
    "             objective='val_accuracy',\n",
    "             max_trials=5,\n",
    "             directory = \"Neural_network_results\",\n",
    "             project_name = \"Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cbc064d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.6169999837875366\n",
      "\n",
      "Best val_accuracy So Far: 0.9850000143051147\n",
      "Total elapsed time: 00h 00m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, \n",
    "             validation_data = (X_test, y_test), \n",
    "             epochs = 5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6871f6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 64, 'optimizer': 'adam', 'loss': 'squared_hinge'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1264c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "90bfd3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                9408      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13633 (53.25 KB)\n",
      "Trainable params: 13633 (53.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec2c0b",
   "metadata": {},
   "source": [
    " - Hyperparameter tunning with number of neurons in layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "463e772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "\n",
    "  #1st layer of neural network\n",
    "  for i in range(hp.Int('num_layers', 2, 20)):\n",
    "    model.add(Dense(units = hp.Int(\"units_\" + str(i),\n",
    "                                   min_value = 8,\n",
    "                                   max_value = 512,\n",
    "                                   step = 8),\n",
    "                    kernel_initializer = 'he_uniform',\n",
    "                    activation='relu',\n",
    "                    input_dim = 146,))\n",
    "    \n",
    "  #2nd layer of neural network\n",
    "  model.add(Dense(units = 8,\n",
    "                  kernel_initializer = 'he_uniform',\n",
    "                  activation='relu',))\n",
    "  #3rd layer of neural network(i.e. output layer)\n",
    "  model.add(Dense(1,\n",
    "                  activation='sigmoid'))\n",
    "\n",
    "  \n",
    "    #Optimizers to be used in different different layers of neural network\n",
    "  optimizer = hp.Choice(\"optimizer\", values =['adam', 'sgd', 'rmsprop', 'adadelta'])\n",
    "  #Loss function to be used in different different layers of neural network\n",
    "  loss = hp.Choice(\"loss\", values =['binary_crossentropy', 'hinge', 'sigmoid_focal_crossentropy', 'squared_hinge', 'kullback_leibler_divergence', 'mean_squared_error'])\n",
    "  #Constructing the neural network model\n",
    "  model.compile(optimizer = optimizer, loss = loss, metrics = 'accuracy')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bcb9b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from Neural_network_results_new\\Hyperparameter_tunning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_second = RandomSearch(build_model,\n",
    "                            objective = 'val_accuracy',\n",
    "                            max_trials = 5,\n",
    "                            directory = \"Neural_network_results_new\",\n",
    "                            project_name = \"Hyperparameter_tunning\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7e8fc65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_second.search(X_train, y_train,\n",
    "                    validation_data = (X_test, y_test), \n",
    "                    epochs = 15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e19307c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 2,\n",
       " 'units_0': 144,\n",
       " 'units_1': 432,\n",
       " 'optimizer': 'adam',\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'units_2': 200,\n",
       " 'units_3': 504}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_second.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7a004824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    }
   ],
   "source": [
    "new_best_model = tuner_second.get_best_models(num_models = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cff09222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 144)               21168     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 432)               62640     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 3464      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87281 (340.94 KB)\n",
      "Trainable params: 87281 (340.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c43c8c",
   "metadata": {},
   "source": [
    "## **Let's create a pipeline for our neural network**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d702b0a",
   "metadata": {},
   "source": [
    "### 1. **Function for Data Ingestion**\n",
    "\n",
    "Required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0c2a738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1da00e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KUSHAL\\AppData\\Local\\Temp\\ipykernel_20468\\3404038531.py:8: DtypeWarning: Columns (81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "def data_ingestion(file_path: str)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loading the CSV file\n",
    "    Args: \n",
    "        - file_path: File path to the CSV file\n",
    "    Returns: The give function will return the CSV file into a converted DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "df = data_ingestion('aps_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ee879",
   "metadata": {},
   "source": [
    "### 2. **Function for Data Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aee88290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bb00a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "NULL_THRESHOLD = 0.2\n",
    "TARGET_FEATURE = \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7de4608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(df: pd.DataFrame, null_threshold: float, target_column: str):\n",
    "    \"\"\"\n",
    "    Tranforming the data frame.\n",
    "    Here, we'll be taking the DataFrame removing the columns with having more than 20%\n",
    "    of null values and applying knn imputation on the columns present in the DataFrame.\n",
    "    Args: \n",
    "        - file_path: File path to the CSV fxile\n",
    "    Returns: The given function will transform the DataFrame and the list of required columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def transforming_null_data(df: pd.DataFrame)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This replace the 'na' values by np.nan\n",
    "        Args: \n",
    "            - df: DataFrame to be transformed\n",
    "        Returns: The given function will return the converted DataFrame.\n",
    "        \"\"\"\n",
    "        df = df.replace('na', np.nan)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def list_required_columns(df: pd.DataFrame)->List:\n",
    "        \"\"\"\n",
    "        This will create a list of required columns for the model.\n",
    "        Args: \n",
    "            - df: DataFrame to be transformed\n",
    "            - null_threshold: Accepted percentage of null data in a column\n",
    "        Returns: The given function will return the list of desired column in the DataFrame.\n",
    "        \"\"\"\n",
    "        return [column for column in df.columns if df[column].isnull().sum()/len(df[column]) < null_threshold]\n",
    "    \n",
    "    def filtered_dataframe(df: pd.DataFrame, filtered_columns: List) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This function will create the dataframe using the required list of columns.\n",
    "        Args: \n",
    "            - df: DataFrame to be transformed\n",
    "            - filtered_columns: List of required columns for the dataframe.\n",
    "        Returns: The given function will return the transformed dataframe.\n",
    "        \"\"\"\n",
    "        df = df[filtered_columns]\n",
    "        return df\n",
    "    \n",
    "    def list_input_features(list_features:List) -> List:\n",
    "        \"\"\"\n",
    "        This function will create list of input features.\n",
    "        Args: \n",
    "            - list_features: List of required columns for the dataframe\n",
    "            - target_feature: Column name of target feature\n",
    "        Returns: The given function will return the list of input features.\n",
    "        \"\"\"\n",
    "        return [column for column in list_features if column not in [target_column]]\n",
    "    \n",
    "    def encoding_features(df : pd.DataFrame, input_features: List) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This function will encode the target feature in the DataFrame.\n",
    "        Args: \n",
    "            - df: DataFrame to be transformed\n",
    "            - target_column: Name of the target column\n",
    "        Returns: The given function will return the dataframe with encoded target column.\n",
    "        \"\"\"\n",
    "        df[target_column]=pd.get_dummies(df[target_column],drop_first=True)\n",
    "        df[input_features] = df[input_features].astype(float)\n",
    "        return df\n",
    "    \n",
    "    def imputing_missing_data(df: pd.DataFrame, list_columns: List) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This function will impute the np.nan values in the DataFrame.\n",
    "        Args: \n",
    "            - df: DataFrame to be transformed\n",
    "        Returns: The given function will return the imputed version of dataframe.\n",
    "        \"\"\"\n",
    "        #Creating instance of KNNImputer\n",
    "        knn_imputer = KNNImputer(n_neighbors=3)\n",
    "        #Applying fit_transform()\n",
    "        imputed_data = knn_imputer.fit_transform(df)\n",
    "        #Converting the imputed version of DataFrame back to DataFrame as the return type of KNNInputer() is numpy.array\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=list_columns)\n",
    "\n",
    "        return imputed_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataframe = transforming_null_data(df)\n",
    "    columns_required = list_required_columns(df = dataframe)\n",
    "    input_features = list_input_features(list_features = columns_required)\n",
    "    dataframe = filtered_dataframe(df = dataframe, filtered_columns = columns_required)\n",
    "    dataframe = encoding_features(df = dataframe, input_features = input_features)\n",
    "    dataframe = imputing_missing_data(df = dataframe, list_columns = columns_required)\n",
    "    dataframe[target_column] = dataframe[target_column].astype(int) \n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3ca82d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_transformation(df = df, null_threshold = NULL_THRESHOLD, target_column = TARGET_FEATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7d5bf616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>ag_004</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>480.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>3598.0</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>8524.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>4980.0</td>\n",
       "      <td>13632.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  aa_000  ac_000  ae_000  af_000  ag_000  ag_001  ag_002  ag_003  \\\n",
       "0      0     6.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1      0    90.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2      0    30.0    16.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3      0   444.0    14.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4      0    82.0    12.0     0.0     0.0     0.0     0.0  1464.0  4980.0   \n",
       "\n",
       "    ag_004  ...  ee_002  ee_003  ee_004  ee_005  ee_006  ee_007  ee_008  \\\n",
       "0    614.0  ...    26.0     8.0    26.0    52.0     0.0     0.0     0.0   \n",
       "1     10.0  ...  1268.0   526.0   554.0   300.0   118.0   260.0     0.0   \n",
       "2    120.0  ...   480.0    84.0    74.0    50.0    46.0     0.0     0.0   \n",
       "3  17950.0  ...  1614.0  1144.0  3598.0  2460.0  1258.0  8524.0   110.0   \n",
       "4  13632.0  ...  1010.0   132.0   310.0    56.0    92.0  1292.0     0.0   \n",
       "\n",
       "   ee_009  ef_000  eg_000  \n",
       "0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c73298",
   "metadata": {},
   "source": [
    "### 3. **Function for preparing DataFrame for Training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cefeb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "10c1cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "TARGET_FEATURE = \"class\"\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "807b8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_data(df : pd.DataFrame, random_state:int, target_column:str, test_size:float) -> pd.DataFrame:\n",
    "    \"\"\"\"\n",
    "    Preparing the dataset for training.\n",
    "    Here, we'll be taking the DataFrame splitting the data into Independent features \n",
    "    and dependent features and then again splitting them for training and testing.\n",
    "    Args: \n",
    "        - df: DataFrame\n",
    "        - training_data: percentage of training data\n",
    "    Returns: The given function will return the training and testing datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    def splitting_data(df : pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\"\n",
    "        Splitting the dataset into Independent features and dependent features.\n",
    "        Args: \n",
    "            - df: DataFrame\n",
    "        Returns: The given function will return two dataframes one containing Input and \n",
    "                 the other will contain target features.\n",
    "        \"\"\"\n",
    "        X = df.drop(columns = target_column)\n",
    "        y = df[target_column]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def train_test_data(X : pd.DataFrame, y : pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\"\n",
    "        Splitting the X and y dataset into train test split and applying standard scalar.\n",
    "        Args: \n",
    "            - X: DataFrame containing input features\n",
    "            - y: DataFrame containing target feature\n",
    "        Returns: The given function will return four dataframes. For each of the independent\n",
    "                 and taget there will be train and test dataframe.\n",
    "        \"\"\"\n",
    "\n",
    "        X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = test_size, random_state = random_state)\n",
    "\n",
    "        sscalar = StandardScaler()\n",
    "        X_train = sscalar.fit_transform(X_train)\n",
    "        X_test = sscalar.transform(X_test)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    X, y = splitting_data(df = df)\n",
    "    X_train, X_test, y_train, y_test = train_test_data(X = X, y = y)\n",
    "\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f535be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preparing_data(df = data, random_state = RANDOM_STATE, target_column = TARGET_FEATURE, test_size = TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfda36",
   "metadata": {},
   "source": [
    "### 4. **Function for Model Training using ANN in Tensforflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "23b9cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1962f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.25\n",
    "INPUT_DIMENSION = 146\n",
    "OUT_DIMENSION_LAYER1 = 10\n",
    "OUT_DIMENSION_LAYER2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7c89de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(input_dim: int, X_train: np.array, y_train: np.array, batch_size: int, epochs : int, validation_split : float, layer1_out_dim: int, layer2_out_dim: int):\n",
    "\n",
    "    def build_neural_network():\n",
    "\n",
    "        classifier = Sequential()\n",
    "        classifier.add(Dense(units=layer1_out_dim,kernel_initializer='he_uniform',activation='relu',input_dim = input_dim))\n",
    "        classifier.add(Dense(units = layer2_out_dim, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "        classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "        classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "        return classifier, classifier.summary()\n",
    "\n",
    "    def neural_network_training(neural_network: tensorflow.keras.models.Sequential, ):\n",
    "\n",
    "        model_training = neural_network.fit(X_train,y_train,batch_size=10,epochs=30,validation_split=0.25)\n",
    "\n",
    "        return model_training, model_training.history['accuracy']\n",
    "\n",
    "\n",
    "    neural_network_model, neural_network_info = build_neural_network()\n",
    "    #Save details of neural network\n",
    "    trained_model, trained_model_summary = neural_network_training(neural_network_model)\n",
    "    #Save details of neural network\n",
    "\n",
    "    return neural_network_model, neural_network_info, trained_model, trained_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ec1f5349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 10)                1470      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1591 (6.21 KB)\n",
      "Trainable params: 1591 (6.21 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 2s 4ms/step - loss: 0.1941 - accuracy: 0.9753 - val_loss: 0.0932 - val_accuracy: 0.9770\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9847 - val_loss: 0.0639 - val_accuracy: 0.9800\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9873 - val_loss: 0.0446 - val_accuracy: 0.9830\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9903 - val_loss: 0.0587 - val_accuracy: 0.9840\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0353 - val_accuracy: 0.9860\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0339 - val_accuracy: 0.9870\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.0290 - val_accuracy: 0.9900\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0297 - val_accuracy: 0.9880\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.0384 - val_accuracy: 0.9880\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0426 - val_accuracy: 0.9870\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0407 - val_accuracy: 0.9870\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0402 - val_accuracy: 0.9890\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0364 - val_accuracy: 0.9900\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0333 - val_accuracy: 0.9890\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0507 - val_accuracy: 0.9890\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9960 - val_loss: 0.0446 - val_accuracy: 0.9890\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0428 - val_accuracy: 0.9880\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0405 - val_accuracy: 0.9910\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0462 - val_accuracy: 0.9900\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0457 - val_accuracy: 0.9850\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0385 - val_accuracy: 0.9900\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0309 - val_accuracy: 0.9890\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0321 - val_accuracy: 0.9900\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0372 - val_accuracy: 0.9900\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0379 - val_accuracy: 0.9890\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0544 - val_accuracy: 0.9880\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0511 - val_accuracy: 0.9900\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.0489 - val_accuracy: 0.9880\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0553 - val_accuracy: 0.9880\n"
     ]
    }
   ],
   "source": [
    "nn_model, nn_model_summary, nn_model_trained, nn_model_trained_summary = model_training(input_dim = INPUT_DIMENSION, X_train = X_train, y_train = y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_split = VALIDATION_SPLIT, layer1_out_dim = OUT_DIMENSION_LAYER1, layer2_out_dim = OUT_DIMENSION_LAYER2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f81562",
   "metadata": {},
   "source": [
    "### Understanding the construction of the neural network:\n",
    "\n",
    "```python\n",
    "classifier=Sequential()\n",
    "```\n",
    "Here, we are creating an object `classifier` having an instannce of `tensorflow.keras.models.Sequential` which will allow us to create interconnected layers in the neural network. \n",
    "\n",
    "```python\n",
    "classifier.add(Dense(units=10,kernel_initializer='he_uniform',activation='relu',input_dim =146))\n",
    "```\n",
    "\n",
    "As the classifier object is the instance of Sequential Neural Network, to create layers for the neural network. Here, we are creating the first layer i.e. input layer of $146$ dimension and each neuron will be having $10$ outputs. Here, `'he_normal'` been used as weight initialization technique as the activation is `'relu'`.\n",
    "\n",
    "```python\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
    "```\n",
    "\n",
    "Here, we are creating the second layer where each neuron will be having $10$ outputs, `'he_normal'` as weight initialization technique and `'relu'` as activation function.\n",
    "\n",
    "```python\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "```\n",
    "\n",
    "Here, we are creating the third layer where it will produce the output. Since its a classification thus third layer will be having one output. Since, the third layer will do the final classification, thus we are using `'sigmoid'` as activation function and `'glorot_normal'` as kernel_initializer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a692ece",
   "metadata": {},
   "source": [
    "### 5. **Model Prediction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "232e4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, X_test: pd.DataFrame)->pd.DataFrame:\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_pred = [1 if data>0.5 else 0 for data in y_pred ]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5a8d0f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_prediction(model = nn_model, \n",
    "                          X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4de8f",
   "metadata": {},
   "source": [
    "### 6. **Function for Model Evaluation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "917e6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cea5acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_pred, y_test, trained_model):\n",
    "\n",
    "    def confusion_matrix_():\n",
    "        # Plot the confusion matrix as a heatmap using matplotlib\n",
    "        plt.imshow(confusion_matrix(y_test, y_pred), \n",
    "                   interpolation='nearest', \n",
    "                   cmap=plt.cm.Blues)\n",
    "\n",
    "        # Add color bar\n",
    "        plt.colorbar()\n",
    "\n",
    "        # Add labels, title, and axis ticks\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('model_confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "    def training_model_loss_summary():\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(trained_model.history['loss'])\n",
    "        plt.plot(trained_model.history['val_loss'])\n",
    "        plt.title('Model loss summary')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.savefig('model_accuracy_summary.png')\n",
    "        plt.close()\n",
    "\n",
    "    def training_model_accuracy_summary():\n",
    "        plt.plot(trained_model.history['accuracy'])\n",
    "        plt.plot(trained_model.history['val_accuracy'])\n",
    "        plt.title('Model accuracy summary')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.savefig('model_loss_summary.png')\n",
    "        plt.close()\n",
    "\n",
    "    confusion_matrix_()\n",
    "    training_model_loss_summary()\n",
    "    training_model_accuracy_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "eda1720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(y_pred = y_pred, \n",
    "                 y_test = y_test, \n",
    "                 trained_model = nn_model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a12dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
